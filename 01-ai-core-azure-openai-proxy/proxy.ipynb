{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install AI Core Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install ai-core-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "import yaml\n",
    "from IPython.display import clear_output\n",
    "from pprint import pprint\n",
    "\n",
    "from ai_core_sdk.models import ParameterBinding, Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "aic_service_key_path = \"./resources/aic_service_key.json\"\n",
    "git_setup_file_path = \"./resources/git_setup.json\"\n",
    "docker_secret_file_path = \"./resources/docker_secret.json\"\n",
    "env_file_path = \"./resources/env.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Connect to your AI Core instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Library\n",
    "with open(aic_service_key_path) as ask:\n",
    "    aic_service_key = json.load(ask)\n",
    "\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "\n",
    "# Create Connection\n",
    "ai_core_client = AICoreV2Client(\n",
    "    base_url = aic_service_key[\"serviceurls\"][\"AI_API_URL\"] + \"/v2\", # The present AI API version is 2\n",
    "    auth_url=  aic_service_key[\"url\"] + \"/oauth/token\",\n",
    "    client_id = aic_service_key[\"clientid\"],\n",
    "    client_secret = aic_service_key[\"clientsecret\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Returns no output*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "response = ai_core_client.repositories.query()\n",
    "print(response.count) # Should return integer value else your values in above step are incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Onboard the Git repository that contains the templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AIAPIServerException",
     "evalue": "Failed to post /admin/repositories: A repository with name 'azure-openai-aicore' already exists \n Status Code: 409, Request ID:None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAIAPIServerException\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(git_setup_file_path) \u001b[39mas\u001b[39;00m gs:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \t\tgit_key \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(gs)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m ai_core_client\u001b[39m.\u001b[39;49mrepositories\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     name \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mazure-openai-aicore\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     url \u001b[39m=\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhttps://github.com/\u001b[39;49m\u001b[39m{\u001b[39;49;00mgit_key[\u001b[39m'\u001b[39;49m\u001b[39musername\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39m/azure-openai-aicore-cap-api\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m# Forked repo\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     username \u001b[39m=\u001b[39;49m git_key[\u001b[39m\"\u001b[39;49m\u001b[39musername\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     password \u001b[39m=\u001b[39;49m git_key[\u001b[39m\"\u001b[39;49m\u001b[39mpassword\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m )\n",
      "File \u001b[0;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/.venv/lib/python3.10/site-packages/ai_core_sdk/resource_clients/repositories_client.py:38\u001b[0m, in \u001b[0;36mRepositoriesClient.create\u001b[0;34m(self, name, url, username, password)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"On-boards a new GitOps repository\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[39m:param name: name of the GitOps repository\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m:rtype: class:`ai_core_sdk.models.base_models.BasicNameResponse`\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m body \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: name, \u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m: url, \u001b[39m'\u001b[39m\u001b[39musername\u001b[39m\u001b[39m'\u001b[39m: username, \u001b[39m'\u001b[39m\u001b[39mpassword\u001b[39m\u001b[39m'\u001b[39m: password}\n\u001b[0;32m---> 38\u001b[0m response_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrest_client\u001b[39m.\u001b[39;49mpost(path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__PATH, body\u001b[39m=\u001b[39;49mbody)\n\u001b[1;32m     39\u001b[0m \u001b[39mreturn\u001b[39;00m Message\u001b[39m.\u001b[39mfrom_dict(response_dict)\n",
      "File \u001b[0;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/.venv/lib/python3.10/site-packages/ai_api_client_sdk/helpers/rest_client.py:146\u001b[0m, in \u001b[0;36mRestClient.post\u001b[0;34m(self, path, body, headers, resource_group)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\u001b[39mself\u001b[39m, path: \u001b[39mstr\u001b[39m, body: Dict[\u001b[39mstr\u001b[39m, Union[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, headers: Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    119\u001b[0m          resource_group: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m    120\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Sends a POST request to the server.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[39m    :param path: path of the endpoint the request should be sent to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m    :rtype: dict\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_request(\u001b[39m'\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m'\u001b[39;49m, path\u001b[39m=\u001b[39;49mpath, body_json\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders, resource_group\u001b[39m=\u001b[39;49mresource_group)\n",
      "File \u001b[0;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/.venv/lib/python3.10/site-packages/ai_api_client_sdk/helpers/rest_client.py:110\u001b[0m, in \u001b[0;36mRestClient._handle_request\u001b[0;34m(self, method, path, params, body_json, headers, resource_group)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[39mraise\u001b[39;00m AIAPIPreconditionFailedException(description\u001b[39m=\u001b[39merror_description, error_message\u001b[39m=\u001b[39merror_message,\n\u001b[1;32m    107\u001b[0m                                                error_code\u001b[39m=\u001b[39merror_code, request_id\u001b[39m=\u001b[39mrequest_id,\n\u001b[1;32m    108\u001b[0m                                                details\u001b[39m=\u001b[39merror_details)\n\u001b[1;32m    109\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m         \u001b[39mraise\u001b[39;00m AIAPIServerException(status_code\u001b[39m=\u001b[39mstatus_code, description\u001b[39m=\u001b[39merror_description,\n\u001b[1;32m    111\u001b[0m                                    error_message\u001b[39m=\u001b[39merror_message, error_code\u001b[39m=\u001b[39merror_code, request_id\u001b[39m=\u001b[39mrequest_id,\n\u001b[1;32m    112\u001b[0m                                    details\u001b[39m=\u001b[39merror_details)\n\u001b[1;32m    113\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m100\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m AIAPIServerException(description\u001b[39m=\u001b[39merror_description, error_message\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mtext,\n\u001b[1;32m    115\u001b[0m                                status_code\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mstatus_code)\n",
      "\u001b[0;31mAIAPIServerException\u001b[0m: Failed to post /admin/repositories: A repository with name 'azure-openai-aicore' already exists \n Status Code: 409, Request ID:None"
     ]
    }
   ],
   "source": [
    "# WARNING: Refrain from onboarding again if previously onboarded\n",
    "#  else you will get AIAPIServerException 409\n",
    "\n",
    "with open(git_setup_file_path) as gs:\n",
    "\t\tgit_key = json.load(gs)\n",
    "\n",
    "ai_core_client.repositories.create(\n",
    "    name = \"azure-openai-aicore\",\n",
    "    url = f\"https://github.com/{git_key['username']}/azure-openai-aicore-cap-api\", # Forked repo\n",
    "    username = git_key[\"username\"],\n",
    "    password = git_key[\"password\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check onboarded repositories\n",
    "response = ai_core_client.repositories.query()\n",
    "#\n",
    "for repository in response.resources:\n",
    "    print('Name:', repository.name)\n",
    "    print('URL:', repository.url)\n",
    "    print('Status:', repository.status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Output*\n",
    "\n",
    "```\n",
    "...\n",
    "Name: azure-openai-aicore\n",
    "URL: https://github.com/john/azure-openai-aicore-cap-api\n",
    "Status: RepositoryStatus.COMPLETED\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Register an application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ai_api_client_sdk.models.base_models.BasicResponse at 0x7fa76409ae60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARNING: Run only once\n",
    "\n",
    "ai_core_client.applications.create(\n",
    "    repository_url = f\"https://github.com/{git_key['username']}/azure-openai-aicore-cap-api\",\n",
    "    path = \"01-ai-core-azure-openai-proxy/scenario\", # Scan this folder for instruction YAML files\n",
    "    revision = \"HEAD\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'azure-openai-proxy', 'name': 'Azure OpenAI Proxy', 'description': 'Azure OpenAI  Proxy', 'labels': None, 'created_at': datetime.datetime(2023, 10, 21, 17, 46, 41), 'modified_at': datetime.datetime(2023, 10, 21, 17, 46, 41)}\n"
     ]
    }
   ],
   "source": [
    "# List scenarios scanned by the application created above\n",
    "response = ai_core_client.scenario.query(resource_group='default')\n",
    "\n",
    "for scenario in response.resources:\n",
    "    print(scenario.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Output*\n",
    "\n",
    "```\n",
    "...\n",
    "{'id': 'azure-openai-proxy', 'name': 'Azure OpenAI Proxy', 'description': 'Azure OpenAI  Proxy', 'labels': None, ...)}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Docker Hub (optional)\n",
    "#### 4.1 Register Docker secret on SAP BTP, AI Core (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'secret has been created'}\n"
     ]
    }
   ],
   "source": [
    "with open(docker_secret_file_path) as dsf:\n",
    "    docker_secret = json.load(dsf)\n",
    "\n",
    "\n",
    "response = ai_core_client.docker_registry_secrets.create(\n",
    "    name = docker_secret[\"name\"],\n",
    "    data = docker_secret[\"data\"]\n",
    ")\n",
    "\n",
    "print(response.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Output*\n",
    "\n",
    "```\n",
    "{'message': 'secret has been created'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Build and push Docker image (optional)\n",
    "```\n",
    "$ cd proxy\n",
    "$ docker build -t {DOCKER_USERNAME}/azure-openai-proxy .\n",
    "$ docker push {DOCKER_USERNAME}/azure-openai-proxy\n",
    "```\n",
    "\n",
    "THROUGH THE DOCKER CLI.  \n",
    "See: https://developers.sap.com/tutorials/ai-core-aiapi-clientsdk-workflows.html#f824a41d-efe8-4883-8238-caef4ac5f789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a resource group (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Free Tier AI Core Serice:\n",
    "#  you will not be able to create a new resource group.\n",
    "#  resource group named `default` exists in all systems.\n",
    "#  cell execution does not impact existing contents\n",
    "#\n",
    "# For paid AI Core service: \n",
    "#  IF you wish execute this step\n",
    "#  You are NOT REQUIRED TO RE-EXECUTE or Redo previous completed steps.\n",
    "#  Ensure that in the steps that follows modify with your resource group name\n",
    "\n",
    "resource_group_id = \"default\" # For free tier; `default` exsits in all systems\n",
    "# resource_group_id = \"my-openai-proxy-ns\" # For paid account you can create a namespace aka resource group\n",
    "                                              # Other steps \n",
    "\n",
    "# response = ai_core_client.resource_groups.create(resource_group_id = resource_group_id)\n",
    "# print(response.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create configuration to serve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(env_file_path) as efp:\n",
    "    env_val = json.load(efp)\n",
    "\n",
    "OPENAI_API_BASE = env_val[\"OPENAI_API_BASE\"]\n",
    "OPENAI_API_KEY = env_val[\"OPENAI_API_KEY\"]\n",
    "DOCKER_NAMESPACE = env_val[\"DOCKER_NAMESPACE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '2205fc1d-3f83-431f-91e3-306103d82bc7', 'message': 'Configuration created'}\n"
     ]
    }
   ],
   "source": [
    "# No modification required in below snippet\n",
    "response = ai_core_client.configuration.create(\n",
    "    name = \"azure-proxy-serve\",\n",
    "    scenario_id = \"azure-openai-proxy\",\n",
    "    executable_id = \"azure-openai-proxy\",\n",
    "    input_artifact_bindings = [],\n",
    "    parameter_bindings = [\n",
    "        ParameterBinding(key = \"OPENAI_API_BASE\", value = OPENAI_API_BASE),\n",
    "        ParameterBinding(key = \"OPENAI_API_KEY\", value = OPENAI_API_KEY), \n",
    "        ParameterBinding(key = \"DOCKER_NAMESPACE\", value = DOCKER_NAMESPACE)\n",
    "    ],\n",
    "    resource_group = resource_group_id\n",
    ")\n",
    "\n",
    "\n",
    "serve_config_resp = response\n",
    "print(response.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Actually serve the proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'de24078fdb34610e', 'message': 'Deployment scheduled.', 'deployment_url': '', 'status': <Status.UNKNOWN: 'UNKNOWN'>, 'ttl': None}\n"
     ]
    }
   ],
   "source": [
    "# Start proxy\n",
    "response = ai_core_client.deployment.create(\n",
    "    configuration_id=serve_config_resp.id,\n",
    "    resource_group=resource_group_id\n",
    ")\n",
    "\n",
    "deployment_resp = response\n",
    "print(response.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb Cell 29\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Get Status\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m deployment \u001b[39m=\u001b[39m response \u001b[39m=\u001b[39m ai_core_client\u001b[39m.\u001b[39;49mdeployment\u001b[39m.\u001b[39;49mget(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     deployment_id\u001b[39m=\u001b[39;49mdeployment_resp\u001b[39m.\u001b[39;49mid,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     resource_group\u001b[39m=\u001b[39;49mresource_group_id\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m status \u001b[39m=\u001b[39m deployment\u001b[39m.\u001b[39mstatus\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/01-ai-core-azure-openai-proxy/proxy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m...... deployment status ......\u001b[39m\u001b[39m\"\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/.venv/lib/python3.10/site-packages/ai_api_client_sdk/resource_clients/deployment_client.py:112\u001b[0m, in \u001b[0;36mDeploymentClient.get\u001b[0;34m(self, deployment_id, resource_group, select)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[39mreturn\u001b[39;00m DeploymentGetStatusResponse\u001b[39m.\u001b[39mfrom_dict(deployment_dict)\n\u001b[1;32m    111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     deployment_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrest_client\u001b[39m.\u001b[39;49mget(path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/deployments/\u001b[39;49m\u001b[39m{\u001b[39;49;00mdeployment_id\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m, resource_group\u001b[39m=\u001b[39;49mresource_group)\n\u001b[1;32m    113\u001b[0m     \u001b[39mreturn\u001b[39;00m Deployment\u001b[39m.\u001b[39mfrom_dict(deployment_dict)\n",
      "File \u001b[0;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/.venv/lib/python3.10/site-packages/ai_api_client_sdk/helpers/rest_client.py:176\u001b[0m, in \u001b[0;36mRestClient.get\u001b[0;34m(self, path, params, headers, resource_group)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, path: \u001b[39mstr\u001b[39m, params: Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, headers: Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    149\u001b[0m         resource_group: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[\u001b[39mdict\u001b[39m, \u001b[39mint\u001b[39m]:\n\u001b[1;32m    150\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Sends a GET request to the server.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \n\u001b[1;32m    152\u001b[0m \u001b[39m    :param path: path of the endpoint the request should be sent to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39m    :rtype: Union[dict, int]\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_request(\u001b[39m'\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m'\u001b[39;49m, path\u001b[39m=\u001b[39;49mpath, params\u001b[39m=\u001b[39;49mparams, headers\u001b[39m=\u001b[39;49mheaders, resource_group\u001b[39m=\u001b[39;49mresource_group)\n",
      "File \u001b[0;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/.venv/lib/python3.10/site-packages/ai_api_client_sdk/helpers/rest_client.py:81\u001b[0m, in \u001b[0;36mRestClient._handle_request\u001b[0;34m(self, method, path, params, body_json, headers, resource_group)\u001b[0m\n\u001b[1;32m     79\u001b[0m     params \u001b[39m=\u001b[39m humps\u001b[39m.\u001b[39mcamelize(params)\n\u001b[1;32m     80\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     response \u001b[39m=\u001b[39m requests_function(url\u001b[39m=\u001b[39;49murl, params\u001b[39m=\u001b[39;49mparams, json\u001b[39m=\u001b[39;49mbody_json, headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m     82\u001b[0m                                  timeout\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect_timeout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_timeout))\n\u001b[1;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[1;32m     84\u001b[0m         \u001b[39mraise\u001b[39;00m AIAPIAuthorizationException(description\u001b[39m=\u001b[39merror_description, error_message\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mtext)\n",
      "File \u001b[0;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/.venv/lib/python3.10/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/.venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/.venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/.venv/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    792\u001b[0m     conn,\n\u001b[1;32m    793\u001b[0m     method,\n\u001b[1;32m    794\u001b[0m     url,\n\u001b[1;32m    795\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    796\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    797\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    798\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    799\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    800\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    801\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    802\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    803\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    804\u001b[0m )\n\u001b[1;32m    806\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    807\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    538\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/mnt/c/Users/ChandanJangid/Downloads/cf_cli/azure-openai-aicore-cap-api/.venv/lib/python3.10/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Poll deployment status.\n",
    "# No modification required in below snipet\n",
    "status = None\n",
    "while status != Status.RUNNING and status != Status.DEAD:\n",
    "    time.sleep(5)\n",
    "    clear_output(wait=True)\n",
    "    # Get Status\n",
    "    #\n",
    "    deployment = response = ai_core_client.deployment.get(\n",
    "        deployment_id=deployment_resp.id,\n",
    "        resource_group=resource_group_id\n",
    "    )\n",
    "    status = deployment.status\n",
    "    print(\"...... deployment status ......\", flush=True)\n",
    "    print(deployment.status)\n",
    "    pprint(deployment.status_details)\n",
    "\n",
    "    if deployment.status == Status.RUNNING:\n",
    "        print(f\"Deployment with {deployment_resp.id} complete!\")\n",
    "\n",
    "# Allow some time for deployment URL to get ready.\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Do an inference request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{deployment.deployment_url}/v2/envs\"\n",
    "headers = {\"Authorization\": ai_core_client.rest_client.get_token(),\n",
    "           \"ai-resource-group\": resource_group_id,\n",
    "           \"Content-Type\": \"application/json\"}\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "legacy_davinci = False # set True if you have a davinci model deployment on Azure OpenAI Services\n",
    "if legacy_davinci:\n",
    "    body = {\n",
    "        \"engine\": \"<YOUR ENGINE>\", # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "                                   #   For information of deployment creation and name Refer article https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal\n",
    "        \"prompt\": \"Classify the following news article into 1 of the following categories: categories: [Business, Tech, Politics, Sport, Entertainment]\\n\\nnews article: Donna Steffensen Is Cooking Up a New Kind of Perfection. The Internet’s most beloved cooking guru has a buzzy new book and a fresh new perspective:\\n\\nClassified category:\",\n",
    "        \"max_tokens\": 60,\n",
    "        \"temperature\": 0,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"top_p\": 1,\n",
    "        \"best_of\": 1,\n",
    "        \"stop\": \"null\"\n",
    "    }\n",
    "    endpoint = f\"{deployment.deployment_url}/v2/completion\"\n",
    "else:\n",
    "    body = {\n",
    "        \"engine\": \"<YOUR ENGINE>\", # include your engine from a deployment of an Azure OpenAI services model\n",
    "        \"prompt\": \"Classify the following news article into 1 of the following categories: categories: [Business, Tech, Politics, Sport, Entertainment]\\n\\nnews article: Donna Steffensen Is Cooking Up a New Kind of Perfection. The Internet’s most beloved cooking guru has a buzzy new book and a fresh new perspective:\\n\\nClassified category:\",\n",
    "        \"max_tokens\": 60,\n",
    "        \"temperature\": 0,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"stop\": \"null\"\n",
    "    }\n",
    "    endpoint = f\"{deployment.deployment_url}/v2/chat-completion\"\n",
    "\n",
    "headers = {\"Authorization\": ai_core_client.rest_client.get_token(),\n",
    "           \"ai-resource-group\": resource_group_id,\n",
    "           \"Content-Type\": \"application/json\"}\n",
    "response = requests.post(endpoint, headers=headers, json=body)\n",
    "\n",
    "print(\"Inference result:\", response.json())\n",
    "pprint(vars(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Kill deployment (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_resp = ai_core_client.deployment.modify(deployment_resp.id,\n",
    "                                                 target_status=Status.STOPPED,\n",
    "                                              resource_group=resource_group_id)\n",
    "status = None\n",
    "while status != Status.STOPPED:\n",
    "    time.sleep(5)\n",
    "    clear_output(wait=True)\n",
    "    deployment = ai_core_client.deployment.get(deployment_resp.id, resource_group=resource_group_id)\n",
    "    status = deployment.status\n",
    "    print(\"...... killing deployment ......\", flush=True)\n",
    "    print(f\"Deployment status: {deployment.status}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c30f2af5f468e7f5b45bcc30fca5f4886c90d54777aed916ed5f6294dfb24bf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
